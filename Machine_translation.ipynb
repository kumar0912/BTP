{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-19 20:16:07,419 : INFO : loading projection weights from C:\\Users\\upend\\Desktop\\6\\model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-19 20:16:09,591 : INFO : loaded (302866, 300) matrix from C:\\Users\\upend\\Desktop\\6\\model.bin\n",
      "2021-01-19 20:16:09,630 : INFO : loading projection weights from C:\\Users\\upend\\Desktop\\48\\model.bin\n",
      "2021-01-19 20:16:10,899 : INFO : loaded (219285, 100) matrix from C:\\Users\\upend\\Desktop\\48\\model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training pairs...\n",
      "Removing missing vocabulary...\n",
      "Amount of missing vocab:  2957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-19 20:16:13,918 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating translation matrix\n",
      "Generated translation matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-a4ccdcd887dc>:62: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.vectors_norm instead).\n",
      "  dists = np.dot(self.syn0norm, vectenter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy @5 is  137 / 1000\n",
      "Accuracy @1 is  65 / 1000\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import os\n",
    "import codecs\n",
    "#import ic\n",
    "import logging\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Log output. Also useful to show program is doing things\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# models trained using gensim implementation of word2vec\n",
    "\n",
    "# Model Link: https://drive.google.com/drive/folders/1Ig-NVfWMGBRJqskfYF2aCh6d7ht-YwG4?usp=sharing\n",
    "print('Loading models...')\n",
    "model_source = KeyedVectors.load_word2vec_format(r'C:\\Users\\upend\\Desktop\\6\\model.bin', binary=True)\n",
    "model_target = KeyedVectors.load_word2vec_format(r'C:\\Users\\upend\\Desktop\\48\\model.bin', binary=True)\n",
    "\n",
    "# list of word pairs to train translation matrix as csv\n",
    "# eg:\n",
    "#  source,target\n",
    "#  今日は、hello\n",
    "#  犬、dog\n",
    "#  猫、cat\n",
    "print ('Reading training pairs...')\n",
    "word_pairs = codecs.open(r'C:\\Users\\upend\\Desktop\\BTP dataset\\dataset1.csv', 'r', 'utf-8')\n",
    "\n",
    "pairs = pd.read_csv(word_pairs)\n",
    "\n",
    "print ('Removing missing vocabulary...')\n",
    "\n",
    "missing = 0\n",
    "\n",
    "for n in range (len(pairs)):\n",
    "\tif pairs['source'][n] not in model_source.vocab or pairs['target'][n] not in model_target.vocab:\n",
    "\t\tmissing = missing + 1\n",
    "\t\tpairs = pairs.drop(n)\n",
    "\n",
    "pairs = pairs.reset_index(drop = True)\n",
    "print('Amount of missing vocab: ', missing)\n",
    "\n",
    "# make list of pair words, excluding the missing vocabs \n",
    "# removed in previous step\n",
    "pairs['vector_source'] = [model_source[pairs['source'][n]] for n in range (len(pairs))]\n",
    "pairs['vector_target'] = [model_target[pairs['target'][n]] for n in range (len(pairs))]\n",
    "\n",
    "# first 5000 from both languages, to train translation matrix\n",
    "source_training_set = pairs['vector_source'][:5000]\n",
    "target_training_set = pairs['vector_target'][:5000]\n",
    "\n",
    "matrix_train_source = pd.DataFrame(source_training_set.tolist()).values\n",
    "matrix_train_target = pd.DataFrame(target_training_set.tolist()).values\n",
    "\n",
    "print('Generating translation matrix')\n",
    "\n",
    "# Matrix W is given in  http://stackoverflow.com/questions/27980159/fit-a-linear-transformation-in-python\n",
    "translation_matrix = np.linalg.pinv(matrix_train_source).dot(matrix_train_target).T\n",
    "print('Generated translation matrix')\n",
    "\n",
    "# Returns list of topn closest vectors to vectenter\n",
    "def most_similar_vector(self, vectenter, topn=5):\n",
    "    self.init_sims()\n",
    "    dists = np.dot(self.syn0norm, vectenter)\n",
    "    if not topn:\n",
    "        return dists\n",
    "    best = np.argsort(dists)[::-1][:topn ]\n",
    "        # ignore (don't return) words from the input\n",
    "    result = [(self.index2word[sim], float(dists[sim])) for sim in best]\n",
    "    return result[:topn]\n",
    "\n",
    "def top_translations(w,numb=5):\n",
    "    val = most_similar_vector(model_target,translation_matrix.dot(model_source[w]),numb)\n",
    "    #print 'traducwithscofres ', val\n",
    "    return val\n",
    "\n",
    "\n",
    "def top_translations_list(w, numb=5):\n",
    "    val = [top_translations(w,numb)[k][0] for k in range(numb)]\n",
    "    return val\n",
    "\n",
    "temp = 1\n",
    "#top_matches = [ pairs['target'][n] in top_translations_list(pairs['source'][n]) for n in range(5000,5003)] \n",
    "\n",
    "# print out source word and translation\n",
    "def display_translations():\n",
    "    for word_num in range(range_start, range_end):\n",
    "        source_word =  pairs['source'][word_num]\n",
    "        translations = top_translations_list(pairs['source'][word_num]) \n",
    "        print (source_word, translations)\n",
    "\n",
    "# range to use to check accuracy\n",
    "range_start = 5000\n",
    "range_end = 6000\n",
    "\n",
    "#display_translations()\n",
    "\n",
    "# now we can check for accuracy on words 5000-6000, 1-5000 used to traning\n",
    "# translation matrix\n",
    "\n",
    "# returns matrix of true or false, true if translation is accuracy, false if not\n",
    "# accurate means the first translation (most similiar vector in target language)\n",
    "# is identical\n",
    "accuracy_at_five = [pairs['target'][n] in top_translations_list(pairs['source'][n]) for n in range(range_start, range_end)]\n",
    "print('Accuracy @5 is ', sum(accuracy_at_five), '/', len(accuracy_at_five))\n",
    "\n",
    "accuracy_at_one = [pairs['target'][n] in top_translations_list(pairs['source'][n],1) for n in range(range_start, range_end)]\n",
    "print('Accuracy @1 is ', sum(accuracy_at_one), '/', len(accuracy_at_one))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
